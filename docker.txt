docker --version
docker info
docker run hello-world
docker run -it ubuntu bash          # runs a ubuntu container terminal
docker image ls 					# list all the images downloaded in the machine
docker container ls 				# list all the running container
docker container ls --all 			# list all the containers

docker inspect --format='{{.LogPath}}' $(docker ps -aqf 'name=workflow_m')


create the Dockerfile which defines what goes inside the container.

# Use an official Python runtime as a parent image
FROM python:2.7-slim

# Set the working directory to /app
WORKDIR /app

# Copy the current directory contents into the container at /app
COPY . /app

# Install any needed packages specified in requirements.txt
RUN pip install --trusted-host pypi.python.org -r requirements.txt

# Make port 80 available to the world outside this container
EXPOSE 80

# Define environment variable
ENV NAME World

# Run app.py when the container launches
CMD ["python", "app.py"]


cd where Dockerfile exists
docker build -t friendly_tag_name .         # builds the image using a tag name
docker run -p 4000:80 friendly_tag_name     # runs the image mapping the machine's port 4000 to the container's port 80
docker run -d -p 4000:80 friendly_tag_name  # runs the container in background in detached mode
docker container stop <container id>        # stops the container


docker login 							# freng0 <solita password>
docker tag friendly_tag_name freng0/get-started:part2		# put the image in the get-started repository using part2 as tag
docker image ls
docker push freng0/get-started:part2  				# upload the image in the repository
docker run -p 4000:80 freng0/get-started:part2 			# run the image in a different way

docker stop $(docker ps -a -q) 				# stop all the docker container 
docker rm $(docker ps -a -q)				  # remove all the docker container
docker system prune -a                # remove all! containers, images, volumes, etc

=================================================================================================================

Stop/delete all containers: 
   docker stop $(docker ps -a -q) 
   docker rm $(docker ps -a -q) 
   docker rm <containerId>
   
Delete all images: 
   docker rmi $(docker images -q)
   docker rmi <imageId> 

=========================================================================================================================================

Services are really just “containers in production.” A service only runs one image, but it codifies the way that image runs—what ports it should use, how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process.

docker-compose.yml (yaml syntax)

version: "3"
services:
  web:
    # replace username/repo:tag with your name and image details
    image: username/repo:tag
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: "0.1"
          memory: 50M
      restart_policy:
        condition: on-failure
    ports:
      - "4000:80"
    networks:
      - webnet
networks:
  webnet:



docker swarm init						# avoid the error “this node is not a swarm manager.”
docker stack deploy -c docker-compose.yml getstartedlab   	# create the service
docker service ls
docker service ps getstartedlab_web 				# list the tasks for each service
docker container ls						# can see the services listing the containers as well

A single container running in a service is called a task. Tasks are given unique IDs that numerically increment, up to the number of replicas you defined in.

docker stack deploy -c docker-compose.yml getstartedlab         # update the docker-compose.yml file for example scaling the number of replicas and re-running the command

docker stack rm getstartedlab					# take the app down
docker swarm leave --force					# take down the swarm
 
==================================================================================================================================

Change dockerd configuration (docker daemon)


1. This commands might be needed if you have permission issues with .docker folder

sudo chown "$USER":"$USER" /home/"$USER"/.docker -R
sudo chmod g+rwx "/home/$USER/.docker" -R

2.

sudo vi /lib/systemd/system/docker.service
Look for the existing ExecStart line:

ExecStart=/usr/bin/docker daemon -H fd://

Add your desired config:

ExecStart=/usr/bin/docker daemon -H fd:// -H tcp://0.0.0.0:3272
Restart:

systemctl daemon-reload
sudo service docker restart

After that, my daemon was listening on 3272 and was ready to go!


============================================================================================================================================
Install docker-machine


base=https://github.com/docker/machine/releases/download/v0.14.0 &&
  curl -L $base/docker-machine-$(uname -s)-$(uname -m) >/tmp/docker-machine &&
  sudo install /tmp/docker-machine /usr/local/bin/docker-machine

docker-machine version

=========================================================================================================================================

Understanding Swarm clusters

A swarm is a group of machines that are running Docker and joined into a cluster. After that has happened, you continue to run the Docker commands you’re used to, but now they are executed on a cluster by a swarm manager. The machines in a swarm can be physical or virtual. After joining a swarm, they are referred to as nodes.

Swarm managers can use several strategies to run containers, such as “emptiest node” -- which fills the least utilized machines with containers. Or “global”, which ensures that each machine gets exactly one instance of the specified container. You instruct the swarm manager to use these strategies in the Compose file, just like the one you have already been using.

Swarm managers are the only machines in a swarm that can execute your commands, or authorize other machines to join the swarm as workers. Workers are just there to provide capacity and do not have the authority to tell any other machine what it can and cannot do.

Up until now, you have been using Docker in a single-host mode on your local machine. But Docker also can be switched into swarm mode, and that’s what enables the use of swarms. Enabling swarm mode instantly makes the current machine a swarm manager. From then on, Docker runs the commands you execute on the swarm you’re managing, rather than just on the current machine.


Set up your swarm

A swarm is made up of multiple nodes, which can be either physical or virtual machines. The basic concept is simple enough: run docker swarm init to enable swarm mode and make your current machine a swarm manager, then run docker swarm join on other machines to have them join the swarm as workers. Choose a tab below to see how this plays out in various contexts. We use VMs to quickly create a two-machine cluster and turn it into a swarm.

docker-machine create --driver virtualbox myvm1  					# create a virtual machine using docker-machine and virtual box as a driver
docker-machine create --driver virtualbox myvm2

Running pre-create checks...
Error with pre-create check: "This computer doesn't have VT-X/AMD-v enabled. Enabling it in the BIOS is mandatory"

(can't run vitualization in your virtualbox ubuntu os)



